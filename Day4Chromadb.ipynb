{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTx83TJIrOJzqzSMuqzhgY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemachandran-D45/vectordb/blob/main/Day4Chromadb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZIZtGHyzD5Z_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def read_file(folder_path):\n",
        "  file_data= []\n",
        "  for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith(\".txt\"):\n",
        "      with open(os.path.join(folder_path,file_name), \"r\") as file:\n",
        "        content = file.read()\n",
        "        file_data.append({\"file_name\": file_name,\"content\":content})\n",
        "\n",
        "  return file_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, I import os module because operating system aloowing us to perform some task with file and directory manupulation. Simply we can say interact with different operating system and manage file, directory, and handling path."
      ],
      "metadata": {
        "id": "MqlB8oxAwN5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function name read_file that having a parameter as folder_path\n",
        "Also having a empty list as file_data will store each .txt file\n",
        "And Loop through file_name in the folder_path\n",
        "os.listdir() get the list of all file inside that folder_path\n",
        "Then Check whether file end with .txt format file_name.endswith(\".txt). if it is the text file then open the file in read mode using\"r\"\n",
        "open(os.path.join(folder_name,file_name) \"r\") then i use read method read()\n",
        "then adding into file_data list as dictionary\n",
        "then return it"
      ],
      "metadata": {
        "id": "8LghopHjwS_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q new_articles.zip -d new_articles"
      ],
      "metadata": {
        "id": "1TlEQFkCy7-h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i upload a zip file from my computer to colab drive which have several text file then extract everything from that . unzip -- we have to use only linux command cuz colab running on linux os. thats why I use os.path.join so if it linux (/forward slash) and if it is window (\\backward slash)"
      ],
      "metadata": {
        "id": "HA4e8IbczHkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"new_articles\"\n",
        "file_data = read_file(folder_path)\n",
        "\n",
        "for data in file_data:\n",
        "  print(f\"File Name : {data['file_name']}\" )\n",
        "  print(f\"Content: {data['content']}\\n\")\n",
        "  print(\"---------\")"
      ],
      "metadata": {
        "id": "T1u7K05vzDp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we setting up the folder_path and calling read_file for loop iterate each dictionary in the file data and print file name and content"
      ],
      "metadata": {
        "id": "1yEFP7OrzKLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = []\n",
        "metadata = []\n",
        "ids = []\n",
        "\n",
        "for index,data in enumerate(file_data):\n",
        "  document.append(data[\"content\"])\n",
        "  metadata.append({\"Source\": data[\"file_name\"]})\n",
        "  ids.append(str(index+1))\n"
      ],
      "metadata": {
        "id": "R3Wi99NM0Xj9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "adding a elements to the document, metadata and ids using for loop"
      ],
      "metadata": {
        "id": "xvH4RDhq1iC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata"
      ],
      "metadata": {
        "id": "tdBaNbBT12bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb -q\n",
        "!pip install sentence-transformers -q"
      ],
      "metadata": {
        "id": "VmYhZHZA13TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from chromadb.config import Settings"
      ],
      "metadata": {
        "id": "OD9iMfh12Dmv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = chromadb.PersistentClient(path=\"new_article_db\")"
      ],
      "metadata": {
        "id": "m1PF9U2a2Qdh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Persistent CLient is used to configure chroma to save and load the db from the local"
      ],
      "metadata": {
        "id": "eTp-WgrxFDfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article_collection = client.create_collection(\"new_article\")"
      ],
      "metadata": {
        "id": "if8_2_7c3kqd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_collection.add(\n",
        "    documents=document,\n",
        "    metadatas=metadata,\n",
        "    ids=ids\n",
        ")"
      ],
      "metadata": {
        "id": "bAnMwCMe33d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an collection using create_collection\n",
        "if we want to retrive exsisting collection just get_collection and for delete, use delete_collection and we can use get_or_create_collection to get collection if it is exsist ro create new collection\n",
        "Then useing add method add a value\n"
      ],
      "metadata": {
        "id": "TitCwk8DFWKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = article_collection.query(\n",
        "    query_texts = \"Who suggest Generative AI\",\n",
        "    n_results = 1\n",
        ")"
      ],
      "metadata": {
        "id": "hQ2X4SIX4plJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "WbjXluED5ltp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = article_collection.query(\n",
        "    query_texts = \"Who is prime minister of england\",\n",
        "    n_results = 1\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "id": "MP9xkew75m1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers -q\n"
      ],
      "metadata": {
        "id": "wB0vYAanGnyU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer(\"paraphrase-MiniLM-L3-v2\")\n"
      ],
      "metadata": {
        "id": "h05arl66Hs88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite use defauld embedding model(L6-v2) we use paraphrase-MiniLM-L3-v2"
      ],
      "metadata": {
        "id": "dGbQmnLXJZvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = []\n",
        "metadata = []\n",
        "ids = []\n",
        "embeddings = []\n",
        "\n",
        "for index,data in enumerate(file_data):\n",
        "  document.append(data[\"content\"])\n",
        "  metadata.append({\"Source\":data[\"file_name\"]})\n",
        "  ids.append(str(index+1))\n",
        "  embedding = model.encode(data[\"content\"]).tolist()\n",
        "  embeddings.append(embedding)\n"
      ],
      "metadata": {
        "id": "lG29qW1LHtwj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_article_emb = client.create_collection(\"new_article_emb\")\n",
        "new_article_emb.add(\n",
        "    documents = document,\n",
        "    metadatas = metadata,\n",
        "    ids = ids,\n",
        "    embeddings=embeddings\n",
        ")"
      ],
      "metadata": {
        "id": "Pfj2VcBgJWBL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"WHo suggest Generative AI\"\n",
        "input_emb = model.encode(query).tolist()\n",
        "result = new_article_emb.query(\n",
        "    query_embeddings= [input_emb],\n",
        "    n_results= 1\n",
        ")\n"
      ],
      "metadata": {
        "id": "ylI3nzVgKSIN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "78i1k6MLLBzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"can you save chatgpt chat?\"\n",
        "input_emb = model.encode(query).tolist()\n",
        "result = new_article_emb.query(\n",
        "    query_embeddings = [input_emb],\n",
        "    n_results= 1\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "id": "8d5nI5szLC30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_article_emb.count()"
      ],
      "metadata": {
        "id": "4oTPgEeVMKma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "count method used to return the number of items in the list and peek() method is used to retun the first 10 items"
      ],
      "metadata": {
        "id": "L40oDoC8J8Og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_1 = new_article_emb.query(\n",
        "    query_embeddings= [input_emb],\n",
        "    n_results = 1,\n",
        "    # where_document ={\"$contains\" : \"who requested\"}\n",
        "    where = {\"Source\" : \"05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\"}\n",
        ")\n"
      ],
      "metadata": {
        "id": "fql2ue3fyfVZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can use where filter to filtered by metadata with associate each documents and where_document to filter by content in the doument."
      ],
      "metadata": {
        "id": "98kpNcCkKMvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_1"
      ],
      "metadata": {
        "id": "1WNpVPQizdif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r \"new_article_db.zip\" \"new_article_dp\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDvPBWt3zes5",
        "outputId": "32014231-ad65-477a-9470-76d55466b480"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: new_article_dp\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r new_article_db.zip . -i new_article_dp)\n"
          ]
        }
      ]
    }
  ]
}