{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPm+GEgudEylYswy5z3c1Kd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemachandran-D45/vectordb/blob/main/Day5Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioNWVo2V4St6",
        "outputId": "d80e9101-c331-49f4-d524-f07855c4daac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ""
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "sec_key = userdata.get(\"Langchain_Testing\")\n",
        "print(sec_key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "OYHpNP-v5khr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "id": "s82KUvU77DpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = sec_key\n",
        "from langchain.llms import HuggingFaceEndpoint\n",
        "\n",
        "\n",
        "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id = repo_id,\n",
        "    temperature=0.5, max_length = 256,\n",
        "    token = sec_key\n",
        ")\n",
        "llm(\"I want to open a restaurant for indian food. suggest a fancy name \")"
      ],
      "metadata": {
        "id": "Z5ZLRvaF5OtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables = [\"cuisine\"],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a only one fancy name for this\"\n",
        "\n",
        ")\n",
        "prompt_template.format(cuisine = \"Indian\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Sz1N8gNB72t8",
        "outputId": "34f52674-4e37-40e7-d29c-a1e31cd60c98"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I want to open a restaurant for Indian food. Suggest a only one fancy name for this'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm,prompt = prompt_template)\n",
        "chain.run(\"American\")"
      ],
      "metadata": {
        "id": "vPJUYklP8u2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Sequential Chain is Where the output of one call is used as the input to the next call"
      ],
      "metadata": {
        "id": "QSuZFWqO9bEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_items =PromptTemplate(\n",
        "    input_variable = [\"restaurant_name\"],\n",
        "    template = \"Suggest some menu items for {restaurant_name}. Resturn it as a comma separated list\"\n",
        ")\n",
        "food_items_chain = LLMChain(llm=llm,prompt=prompt_template_items)\n"
      ],
      "metadata": {
        "id": "799Du1A4-HSE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "chain = SimpleSequentialChain(chains=[chain,food_items_chain])\n",
        "\n",
        "response = chain.run(\"Mexican\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIpY07Q_CgKF",
        "outputId": "17794cd2-6cb2-4385-b7f9-0c7be82a8b72"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "\n",
            "La Belleza Mexicana, El Sabor de las Estrellas, Casa de los Sabores, El Jardin de los Sensores, La Fiesta del Corazon, El Palacio de las Tortillas, La Cocina de los Sueños, El Orgullo Mexicano, La Tierra de los Colores, El Alma de Mexico, La Gran Fiesta, El Refugio del Sabor, La Casa de los Sabores Autenticos, El Sabor del Sol, La Casa de los Tacos, El Sabor de la Vida, La Casa de los Salsas, El Sabor de la Tradicion, La Casa de los Guacamoles, El Sabor de la Pasión.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables = [\"cuisine\"],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a only one fancy name for this\"\n",
        "\n",
        ")\n",
        "name_chain = LLMChain(llm=llm,prompt = prompt_template,output_key=\"restaurant_name\")\n",
        "\n",
        "prompt_template_items=PromptTemplate(\n",
        "    input_variables = [\"restaurant_name\"],\n",
        "    template = \"Suggest some menu items for {restaurant_name}.\"\n",
        "\n",
        ")\n",
        "food_items_chain = LLMChain(llm=llm,prompt=prompt_template_items,output_key=\"menu_items\")\n"
      ],
      "metadata": {
        "id": "1gcTOckkC7md"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "chain = SequentialChain(\n",
        "    chains=[name_chain,food_items_chain],\n",
        "    input_variables=[\"cuisine\"],\n",
        "    output_variables = ['restaurant_name',\"menu_items\"]\n",
        "\n",
        ")\n",
        "chain({'cuisine':\"Italian\"})"
      ],
      "metadata": {
        "id": "tXXt28g_GpRA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
