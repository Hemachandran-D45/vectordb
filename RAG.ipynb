{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcq38Hlvk87A2lcdIuXf1K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemachandran-D45/vectordb/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RAG (Retrival Argument Generation )** is a NLP (Natural language processing) technique that combine the strength of both retrieval and generative based artificial intelligence models.\n",
        "\n",
        "There are three components\n",
        "\n",
        "1) **Load Source Data also called Data ingestion**\n",
        "      The process of collecting data from various source and moving to a central location for storage processing and analysis.\n",
        "      \n",
        "      After ingesting the data we can Load, Transform, Embed\n",
        "      **Load **- Reading from specific data base\n",
        "      **Transform** - Perform Some type of feature engineering techniques and convert that into small chunks.\n",
        "      **Embed** - converting chunks to embedded vector the store\n",
        "\n",
        "2) **Vector Store and Query**\n",
        "      Store that embedded vector into vector storage like chromadb, faiss db. Query into Db\n",
        "\n",
        "3) **Retrieval Similar:**\n",
        "      Retrieve the most similar query as Q&A"
      ],
      "metadata": {
        "id": "EjwJ3q5x2RLw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kAgWTr3Urlb7"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_huggingface -q\n",
        "!pip install langchain_community -q\n",
        "!pip install langchain_core -q\n",
        "!pip install python-dotenv -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "loader = TextLoader(\"/content/speech.txt\")\n",
        "text_documents = loader.load()\n",
        "## Loading a Text"
      ],
      "metadata": {
        "id": "yEFaHTb1vsIm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_documents"
      ],
      "metadata": {
        "id": "grX-_fisywX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "sec_key = userdata.get(\"DwithBappy_Langchain\")\n"
      ],
      "metadata": {
        "id": "99_OexnLyyyA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Environment\n",
        "import os\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = sec_key"
      ],
      "metadata": {
        "id": "vjHZTM_vzkYR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain_community beautifulsoup4"
      ],
      "metadata": {
        "id": "V17KKptv4wK6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful Soup is the library that makes easy to scrape information from the webpage. mostly used scrapping and commonly known as bs4"
      ],
      "metadata": {
        "id": "H2KpNyP3I7jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##web based loader\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "import bs4\n",
        "\n",
        "\n",
        "#load, chunks and index the content of the html page\n",
        "\n",
        "loader= WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "                       bs_kwargs = dict(parse_only = bs4.SoupStrainer(\n",
        "                           class_= (\"post-header\",\"post-footer\",\"post-content\",\"post-title\")\n",
        "                       )))\n"
      ],
      "metadata": {
        "id": "P6xfPEIpzzfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_documents = loader.load()"
      ],
      "metadata": {
        "id": "hQTdiG8z5tMC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_documents"
      ],
      "metadata": {
        "id": "_gCQXmoc6im4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf -q"
      ],
      "metadata": {
        "id": "vSYusYfsJwa9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##pdf loader\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"/content/attention.pdf\")\n",
        "docs = loader.load()\n"
      ],
      "metadata": {
        "id": "lYO5hZlE7iQd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "p3pXeEpv72e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "2RJ5-td69-g5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Splitter\n",
        "\n",
        "    Text Splitter is the most recommented one for generic text.\n",
        "    It is parameterized by a list of character. It tries to split on them in order until chunks are small enough.\n",
        "    The default list is [\"\\n\\n\",\"\\n\",\" \",\"\"] This has the effect of trying to keep all paragraph (sentence and word)\n",
        "    together as long as possible as those word generically seem to be the strongest semantically related peices of text."
      ],
      "metadata": {
        "id": "_6Q8o7AdMFi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 200)\n",
        "documents = text_splitter.split_documents(docs)\n"
      ],
      "metadata": {
        "id": "t6CpHl1nP0qS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb\n",
        "!pip install"
      ],
      "metadata": {
        "id": "NVYhSB5qUxyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken -q"
      ],
      "metadata": {
        "id": "WfMuZeFHm0QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-community faiss-cpu"
      ],
      "metadata": {
        "id": "XuimGMVamMO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Vector Embedding and Vector Store\n",
        "\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "db = Chroma.from_documents(documents[:20],HuggingFaceEmbeddings())"
      ],
      "metadata": {
        "id": "aQ-qO8y1QiXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Vector database\n",
        "\n",
        "query = \"An attention function can be described as mapping a query \"\n",
        "docs = db.similarity_search(query)\n",
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "7OwIYRhaoqwM",
        "outputId": "695b6cdc-f548-4162-aa2a-abb03a62b19f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##FAISS Vector Database\n",
        "\n",
        "from langchain_community.vectorstores import FAISS\n",
        "db1= FAISS.from_documents(documents[:20],HuggingFaceEmbeddings())"
      ],
      "metadata": {
        "id": "uEYiaXxQBuhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"An attention function can be described as mapping a query \"\n",
        "docs = db1.similarity_search(query)\n",
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Zm5ersGdB2LK",
        "outputId": "56f7882a-27f3-43b3-c3ec-169f27fb3c3a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}