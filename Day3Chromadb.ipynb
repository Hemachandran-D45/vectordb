{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPckOglOp5Nrne0Les+DLRA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemachandran-D45/vectordb/blob/main/Day3Chromadb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZIZtGHyzD5Z_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def read_file(folder_path):\n",
        "  file_data= []\n",
        "  for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith(\".txt\"):\n",
        "      with open(os.path.join(folder_path,file_name), \"r\") as file:\n",
        "        content = file.read()\n",
        "        file_data.append({\"file_name\": file_name,\"content\":content})\n",
        "\n",
        "  return file_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, I import os module because operating system aloowing us to perform some task with file and directory manupulation. Simply we can say interact with different operating system and manage file, directory, and handling path."
      ],
      "metadata": {
        "id": "MqlB8oxAwN5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function name read_file that having a parameter as folder_path\n",
        "Also having a empty list as file_data will store each .txt file\n",
        "And Loop through file_name in the folder_path\n",
        "os.listdir() get the list of all file inside that folder_path\n",
        "Then Check whether file end with .txt format file_name.endswith(\".txt). if it is the text file then open the file in read mode using\"r\"\n",
        "open(os.path.join(folder_name,file_name) \"r\") then i use read method read()\n",
        "then adding into file_data list as dictionary\n",
        "then return it"
      ],
      "metadata": {
        "id": "8LghopHjwS_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q new_articles.zip -d new_articles"
      ],
      "metadata": {
        "id": "1TlEQFkCy7-h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i upload a zip file from my computer to colab drive which have several text file then extract everything from that . unzip -- we have to use only linux command cuz colab running on linux os. thats why I use os.path.join so if it linux (/forward slash) and if it is window (\\backward slash)"
      ],
      "metadata": {
        "id": "HA4e8IbczHkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"new_articles\"\n",
        "file_data = read_file(folder_path)\n",
        "\n",
        "for data in file_data:\n",
        "  print(f\"File Name : {data['file_name']}\" )\n",
        "  print(f\"Content: {data['content']}\\n\")\n",
        "  print(\"---------\")"
      ],
      "metadata": {
        "id": "T1u7K05vzDp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we setting up the folder_path and calling read_file for loop iterate each dictionary in the file data and print file name and content"
      ],
      "metadata": {
        "id": "1yEFP7OrzKLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = []\n",
        "metadata = []\n",
        "ids = []\n",
        "\n",
        "for index,data in enumerate(file_data):\n",
        "  document.append(data[\"content\"])\n",
        "  metadata.append({\"Source\": data[\"file_name\"]})\n",
        "  ids.append(str(index+1))\n"
      ],
      "metadata": {
        "id": "R3Wi99NM0Xj9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata"
      ],
      "metadata": {
        "id": "tdBaNbBT12bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb -q\n",
        "!pip install sentence-transformers -q"
      ],
      "metadata": {
        "id": "VmYhZHZA13TC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from chromadb.config import Settings"
      ],
      "metadata": {
        "id": "OD9iMfh12Dmv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = chromadb.PersistentClient(path=\"new_article_db\")"
      ],
      "metadata": {
        "id": "m1PF9U2a2Qdh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_collection = client.create_collection(\"new_article\")"
      ],
      "metadata": {
        "id": "if8_2_7c3kqd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_collection.add(\n",
        "    documents=document,\n",
        "    metadatas=metadata,\n",
        "    ids=ids\n",
        ")"
      ],
      "metadata": {
        "id": "bAnMwCMe33d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = article_collection.query(\n",
        "    query_texts = \"Who suggest Generative AI\",\n",
        "    n_results = 1\n",
        ")"
      ],
      "metadata": {
        "id": "hQ2X4SIX4plJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "WbjXluED5ltp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = article_collection.query(\n",
        "    query_texts = \"Who is prime minister of england\",\n",
        "    n_results = 1\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "id": "MP9xkew75m1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers -q\n"
      ],
      "metadata": {
        "id": "wB0vYAanGnyU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer(\"paraphrase-MiniLM-L3-v2\")\n"
      ],
      "metadata": {
        "id": "h05arl66Hs88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite use defauld embedding model we use paraphrase-MiniLM-L3-v2"
      ],
      "metadata": {
        "id": "dGbQmnLXJZvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = []\n",
        "metadata = []\n",
        "ids = []\n",
        "embeddings = []\n",
        "\n",
        "for index,data in enumerate(file_data):\n",
        "  document.append(data[\"content\"])\n",
        "  metadata.append({\"Source\":data[\"file_name\"]})\n",
        "  ids.append(str(index+1))\n",
        "  embedding = model.encode(data[\"content\"]).tolist()\n",
        "  embeddings.append(embedding)\n"
      ],
      "metadata": {
        "id": "lG29qW1LHtwj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_article_emb = client.create_collection(\"new_article_emb\")\n",
        "new_article_emb.add(\n",
        "    documents = document,\n",
        "    metadatas = metadata,\n",
        "    ids = ids,\n",
        "    embeddings=embeddings\n",
        ")"
      ],
      "metadata": {
        "id": "Pfj2VcBgJWBL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"WHo suggest Generative AI\"\n",
        "input_emb = model.encode(query).tolist()\n",
        "result = new_article_emb.query(\n",
        "    query_embeddings= [input_emb],\n",
        "    n_results= 1\n",
        ")\n"
      ],
      "metadata": {
        "id": "ylI3nzVgKSIN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "78i1k6MLLBzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"can you save chatgpt chat?\"\n",
        "input_emb = model.encode(query).tolist()\n",
        "result = new_article_emb.query(\n",
        "    query_embeddings = [input_emb],\n",
        "    n_results= 1\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "id": "8d5nI5szLC30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4oTPgEeVMKma"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}