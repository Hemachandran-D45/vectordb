{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUfosGngNsZB36KYQJX4O+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemachandran-D45/vectordb/blob/main/Day3Chromadb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZIZtGHyzD5Z_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def read_file(folder_path):\n",
        "  file_data= []\n",
        "  for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith(\".txt\"):\n",
        "      with open(os.path.join(folder_path,file_name), \"r\") as file:\n",
        "        content = file.read()\n",
        "        file_data.append({\"file_name\": file_name,\"content\":content})\n",
        "\n",
        "  return file_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, I import os module because operating system aloowing us to perform some task with file and directory manupulation. Simply we can say interact with different operating system and manage file, directory, and handling path."
      ],
      "metadata": {
        "id": "MqlB8oxAwN5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function name read_file that having a parameter as folder_path\n",
        "Also having a empty list as file_data will store each .txt file\n",
        "And Loop through file_name in the folder_path\n",
        "os.listdir() get the list of all file inside that folder_path\n",
        "Then Check whether file end with .txt format file_name.endswith(\".txt). if it is the text file then open the file in read mode using\"r\"\n",
        "open(os.path.join(folder_name,file_name) \"r\") then i use read method read()\n",
        "then adding into file_data list as dictionary\n",
        "then return it"
      ],
      "metadata": {
        "id": "8LghopHjwS_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q new_articles.zip -d new_articles"
      ],
      "metadata": {
        "id": "1TlEQFkCy7-h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i upload a zip file from my computer to colab drive which have several text file then extract everything from that . unzip -- we have to use only linux command cuz colab running on linux os. thats why I use os.path.join so if it linux (/forward slash) and if it is window (\\backward slash)"
      ],
      "metadata": {
        "id": "HA4e8IbczHkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"new_articles\"\n",
        "file_data = read_file(folder_path)\n",
        "\n",
        "for data in file_data:\n",
        "  print(f\"File Name : {data['file_name']}\" )\n",
        "  print(f\"Content: {data['content']}\\n\")\n",
        "  print(\"---------\")"
      ],
      "metadata": {
        "id": "T1u7K05vzDp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we setting up the folder_path and calling read_file for loop iterate each dictionary in the file data and print file name and content"
      ],
      "metadata": {
        "id": "1yEFP7OrzKLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document = []\n",
        "metadata = []\n",
        "ids = []\n",
        "\n",
        "for index,data in enumerate(file_data):\n",
        "  document.append(data[\"content\"])\n",
        "  metadata.append({\"Source\": data[\"file_name\"]})\n",
        "  ids.append(str(index+1))\n"
      ],
      "metadata": {
        "id": "R3Wi99NM0Xj9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document"
      ],
      "metadata": {
        "id": "tdBaNbBT12bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb -q\n",
        "!pip install sentence-transformers -q"
      ],
      "metadata": {
        "id": "VmYhZHZA13TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from chromadb.config import Settings"
      ],
      "metadata": {
        "id": "OD9iMfh12Dmv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = chromadb.PersistentClient(path=\"new_article_db\")"
      ],
      "metadata": {
        "id": "m1PF9U2a2Qdh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_collection = client.create_collection(\"new_article\")"
      ],
      "metadata": {
        "id": "if8_2_7c3kqd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_collection.add(\n",
        "    documents=document,\n",
        "    metadatas=metadata,\n",
        "    ids=ids\n",
        ")"
      ],
      "metadata": {
        "id": "bAnMwCMe33d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = article_collection.query(\n",
        "    query_texts = \"Who suggest Generative AI\",\n",
        "    n_results = 1\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "hQ2X4SIX4plJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbjXluED5ltp",
        "outputId": "07d70657-7396-4efa-acc8-4d2c7f6fef1c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': [['21']],\n",
              " 'distances': [[0.9466052056705321]],\n",
              " 'metadatas': [[{'Source': '05-05-with-deepfloyd-generative-ai-art-gets-a-text-upgrade.txt'}]],\n",
              " 'embeddings': None,\n",
              " 'documents': [[\"Generative AI is pretty impressive in terms of its fidelity these days, as viral memes like Balenciaga Pope would suggest. The latest systems can conjure up scenescapes from city skylines to cafes, creating images that appear startlingly realistic — at least on first glance.\\n\\nBut one of the longstanding weaknesses of text-to-image AI models is, ironically, text. Even the best models struggle to generate images with legible logos, much less text, calligraphy or fonts.\\n\\nBut that might change.\\n\\nLast week, DeepFloyd, a research group backed by Stability AI, unveiled DeepFloyd IF, a text-to-image model that can “smartly” integrate text into images. Trained on a dataset of more than a billion images and text, DeepFloyd IF, which requires a GPU with at least 16GB of RAM to run, can create an image from a prompt like “a teddy bear wearing a shirt that reads ‘Deep Floyd'” — optionally in a range of styles.\\n\\nDeepFloyd IF is available in open source, licensed in a way that prohibits commercial use — for now. The restriction was likely motivated by the current tenuous legal status of generative AI art models. Several commercial model vendors are under fire from artists who allege the vendors are profiting from their work without compensating them by scraping that work from the web without permission.\\n\\nBut NightCafe, the generative art platform, was granted early access to DeepFloyd IF.\\n\\nNightCafe CEO Angus Russell spoke to TechCrunch about what makes DeepFloyd IF different from other text-to-image models and why it might represent a significant step forward for generative AI.\\n\\nAccording to Russell, DeepFloyd IF’s design was heavily inspired by Google’s Imagen model, which was never released publicly. In contrast to models like OpenAI’s DALL-E 2 and Stable Diffusion, DeepFloyd IF uses multiple different processes stacked together in a modular architecture to generate images.\\n\\nWith a typical diffusion model, the model learns how to gradually subtract noise from a starting image made almost entirely of noise, moving it closer step by step to the target prompt. DeepFloyd IF performs diffusion not once but several times, generating a 64x64px image then upscaling the image to 256x256px and finally to 1024x1024px.\\n\\nWhy the need for multiple diffusion steps? DeepFloyd IF works directly with pixels, Russell explained. Diffusion models are for the most part latent diffusion models, which essentially means they work in a lower-dimensional space that represents a lot more pixels but in a less accurate way.\\n\\nThe other key difference between DeepFloyd IF and models such as Stable Diffusion and DALL-E 2 is that the former uses a large language model to understand and represent prompts as a vector, a basic data structure. Due to the size of the large language model embedded in DeepFloyd IF’s architecture, the model is particularly good at understanding complex prompts and even spatial relationships described in prompts (e.g. “a red cube on top of a pink sphere”).\\n\\n“It’s also very good at generating legible and correctly spelled text in images, and can even understand prompts in multiple languages,” Russell added. “Of these capabilities, the ability to generate legible text in images is perhaps the biggest breakthrough to make DeepFloyd IF stand out from other algorithms.”\\n\\nBecause DeepFloyd IF can pretty capably generate text in images, Russell expects it to unlock a wave of new generative art possibilities — think logo design, web design, posters, billboards and even memes. The model should also be much better at generating things like hands, he says, and — because it can understand prompts in other languages — it might be able to create text in those languages, too.\\n\\n“NightCafe users are excited about DeepFloyd IF largely because of the possibilities that are unlocked by generating text in images,” Russell said. “Stable Diffusion XL was the first open source algorithm to make headway on generating text — it can accurately generate one or two words some of the time — but it’s still not good enough at it for use cases where text is important.”\\n\\nThat’s not to suggest DeepFloyd IF is the holy grail of text-to-image models. Russell notes that the base model doesn’t generate images that are quite as aesthetically pleasing as some diffusion models, although he expects fine-tuning will improve that.\\n\\nBut the bigger question, to me, is to what degree DeepFloyd IF suffers from the same flaws as its generative AI brethren.\\n\\nA growing body of research has turned up racial, ethnic, gender and other forms of stereotyping in image-generating AI, including Stable Diffusion. Just this month, researchers at AI startup Hugging Face and Leipzig University published a tool demonstrating that models including Stable Diffusion and OpenAI’s DALL-E 2 tend to produce images of people that look white and male, especially when asked to depict people in positions of authority.\\n\\nThe DeepFloyd team, to their credit, note the potential for biases in the fine print accompanying DeepFloyd IF:\\n\\nTexts and images from communities and cultures that use other languages are likely to be insufficiently accounted for. This affects the overall output of the model, as white and western cultures are often set as the default.\\n\\nAside from this, DeepFloyd IF, like other open source generative models, could be used for harm, like generating pornographic celebrity deepfakes and graphic depictions of violence. On the official webpage for DeepFloyd IF, the DeepFloyd team says that they used “custom filters” to remove watermarked, “NSFW” and “other inappropriate content” from the training data.\\n\\nBut it’s unclear exactly which content was removed — and how much might’ve been missed. Ultimately, time will tell.\"]],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'included': ['metadatas', 'documents', 'distances']}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MP9xkew75m1C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}